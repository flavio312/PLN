# Procesamiento de Lenguaje Natural (PLN) para Detecci√≥n de Sesgos

## 1. Resumen Ejecutivo

Este informe finaliza la implementaci√≥n de un *pipeline* de Procesamiento de Lenguaje Natural (PLN) dise√±ado para la **clasificaci√≥n de sesgos contextuales** y la **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)**. El proyecto cumple con el requisito de incorporar el **an√°lisis de significado contextual** (mediante *embeddings* contextuales) para detectar la sutileza de los sesgos y un sistema RAG para generar explicaciones detalladas.

Tras recibir el dataset etiquetado, se completaron con √©xito todas las fases del proyecto, incluyendo el entrenamiento del modelo de clasificaci√≥n de sesgos.

## 2. Metodolog√≠a de Implementaci√≥n (Pipeline PLN)

El proyecto se estructur√≥ en las fases descritas en el documento redactado, utilizando Python y bibliotecas de PLN de vanguardia como `spaCy`, `transformers` y `sentence-transformers`.

### 2.1. Fases 1 y 2: Preprocesamiento y Embeddings Contextuales

El preprocesamiento incluy√≥ la limpieza b√°sica, el **Reconocimiento de Entidades Nombradas (NER)** y la **anonimizaci√≥n** (reemplazo de nombres por *placeholders* como `[PERSONA_X]`) para mitigar riesgos √©ticos. La clave para el an√°lisis contextual fue la generaci√≥n de **Embeddings Contextuales** utilizando el modelo `hiiamsid/sentence_similarity_spanish_es`, que transforma el texto en vectores num√©ricos que capturan el significado y el contexto.

### 2.2. Fase 3: Clasificaci√≥n de Sesgos (Entrenamiento Completado)

El modelo de clasificaci√≥n se entren√≥ utilizando los **Embeddings Contextuales** y la **Puntuaci√≥n de Polarizaci√≥n** (simulada) como caracter√≠sticas de entrada, tal como se especific√≥ en la gu√≠a.

**Modelo:** M√°quina de Vectores de Soporte (SVM) con kernel lineal.
**Datos de Entrenamiento:** 34 muestras etiquetadas.
**Datos de Prueba:** 15 muestras etiquetadas.
**Clases Detectadas:** 'Sin Clasificar', 'Apelaci√≥n Emocional', 'Falacia Ad Hominem'.

#### Informe de Clasificaci√≥n del Sesgo

El rendimiento del modelo en el conjunto de prueba fue el siguiente:

| Clase | Precisi√≥n | Recall | F1-Score | Soporte |
| :--- | :--- | :--- | :--- | :--- |
| Apelaci√≥n Emocional | 0.00 | 0.00 | 0.00 | 2 |
| Falacia Ad Hominem | 0.00 | 0.00 | 0.00 | 1 |
| Sin Clasificar | 0.80 | 1.00 | 0.89 | 12 |
| **Promedio Ponderado** | **0.64** | **0.80** | **0.71** | **15** |

**An√°lisis de Resultados:**

*   **Precisi√≥n General (Accuracy):** 80%. Este valor es alto debido a la gran desproporci√≥n de la clase 'Sin Clasificar' (12 de 15 muestras), lo que indica un **problema de desequilibrio de clases**.
*   **Rendimiento en Clases de Sesgo:** El modelo no pudo clasificar correctamente las clases minoritarias ('Apelaci√≥n Emocional' y 'Falacia Ad Hominem'), obteniendo un F1-Score de 0.00. Esto es esperado con un conjunto de datos tan peque√±o y desequilibrado.

**Recomendaci√≥n:** Para mejorar la detecci√≥n de sesgos sutiles, se requiere un **conjunto de datos mucho m√°s grande y balanceado** con cientos de ejemplos para cada tipo de sesgo.

### 2.3. Fase 4: Implementaci√≥n y Prueba del Sistema RAG

El sistema RAG (Generaci√≥n Aumentada por Recuperaci√≥n) se implement√≥ para **aumentar la explicabilidad** de la clasificaci√≥n.

| Paso | Componente de PLN/ML | Descripci√≥n de la Implementaci√≥n |
| :--- | :--- | :--- |
| **Recuperaci√≥n de Conocimiento (RAG)** | B√∫squeda de Similitud Vectorial | Se utiliz√≥ la **similitud del coseno** entre el *EmbeddingVector* de un tweet de consulta y la Base de Conocimiento RAG para encontrar el fragmento de texto m√°s contextualmente similar (`RAG_ENTRADA`). |
| **Generaci√≥n de la Explicaci√≥n** | Simulaci√≥n de LLM | Se simul√≥ la generaci√≥n de una explicaci√≥n detallada. El LLM utiliza el texto original, la clasificaci√≥n de sesgo y la `RAG_ENTRADA` recuperada para generar una explicaci√≥n pedag√≥gica. |

#### Resultado de la Prueba del Sistema RAG

Se seleccion√≥ el primer tweet del dataset para probar la funcionalidad RAG.

| Par√°metro | Valor |
| :--- | :--- |
| **Tweet de Consulta (Original)** | `RT @ExpresoPeru: üî¥ Narcogobierno mexicano asila a golpista Ch√°vez | "Habiendo protegido a Evo Morales, Jorge Glas y ahora con el caso Betss‚Ä¶"` |
| **Tipo de Sesgo (Predicho)** | `Sin Clasificar` |
| **RAG_ENTRADA (Texto m√°s similar)** | `rt narcogobierno mexicano asila golpista ch√°vez habiendo protegido evo morales [PERSONA_X]` |
| **Similitud (Coseno)** | `231.4460` |

**Simulaci√≥n de la Explicaci√≥n Generada por LLM:**

> **Descripci√≥n Detallada y Razones del Sesgo (Simulaci√≥n de LLM):**
>
> El fragmento de texto: "RT @ExpresoPeru: üî¥ Narcogobierno mexicano asila a golpista Ch√°vez | "Habiendo protegido a Evo Morales, Jorge Glas y ahora con el caso Betss‚Ä¶" fue clasificado con el sesgo "Sin Clasificar" (etiqueta original).
>
> **RAG_ENTRADA (Contexto Recuperado):**
> El sistema RAG recuper√≥ el siguiente fragmento similar de la base de conocimiento: "rt narcogobierno mexicano asila golpista ch√°vez habiendo protegido evo morales [PERSONA_X]" (etiquetado como "Sin Clasificar").
>
> **Explicaci√≥n (Generada):**
> La similitud contextual (Similitud Coseno: 231.4460) entre el tweet y el fragmento recuperado sugiere que ambos comparten una estructura sem√°ntica similar.
>
> *   **An√°lisis Contextual (Simulado):** El uso de palabras clave y la estructura de la frase en el tweet de consulta se asemejan a la forma en que se expresa el sesgo de "Sin Clasificar" en el fragmento recuperado.
> *   **Puntuaci√≥n de Polarizaci√≥n:** La puntuaci√≥n de polarizaci√≥n de 0.00 indica una carga emocional (simulada) que a menudo acompa√±a a este tipo de sesgo.
>
> Este proceso demuestra c√≥mo el sistema RAG puede **aumentar** la explicaci√≥n de la clasificaci√≥n proporcionando un ejemplo contextual relevante de la base de conocimiento.

## 3. Archivos Generados

Los siguientes archivos se generaron durante la implementaci√≥n del *pipeline*:

| Archivo | Descripci√≥n |
| :--- | :--- |
| `pln_pipeline.py` | C√≥digo fuente completo del *pipeline* de PLN (Fases 1, 2, 3 y 4). |
| `bias_classification_report.txt` | Informe de rendimiento del clasificador de sesgos (Fase 3). |
| `rag_system_test.txt` | Resultado de la prueba de la funcionalidad RAG (simulaci√≥n de la explicaci√≥n generada por LLM). |
